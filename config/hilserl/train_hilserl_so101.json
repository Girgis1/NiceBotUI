{
  "output_dir": "outputs/train/hilserl_so101",
  "job_name": "hilserl_so101",
  "resume": false,
  "seed": 1000,
  "num_workers": 4,
  "batch_size": 256,
  "steps": 1000000,
  "log_freq": 200,
  "save_checkpoint": true,
  "save_freq": 20000,
  "wandb": {
    "enable": true,
    "project": "hilserl_so101",
    "entity": null,
    "notes": null,
    "run_id": null,
    "mode": null,
    "disable_artifact": false
  },
  "dataset": null,
  "policy": {
    "type": "sac",
    "n_obs_steps": 1,
    "input_features": {
      "observation.images.front": {
        "type": "VISUAL",
        "shape": [
          3,
          128,
          128
        ]
      },
      "observation.images.wrist": {
        "type": "VISUAL",
        "shape": [
          3,
          128,
          128
        ]
      },
      "observation.state": {
        "type": "STATE",
        "shape": [
          6
        ]
      }
    },
    "output_features": {
      "action": {
        "type": "ACTION",
        "shape": [
          4
        ]
      }
    },
    "normalization_mapping": {
      "VISUAL": "MEAN_STD",
      "STATE": "MIN_MAX",
      "ENV": "MIN_MAX",
      "ACTION": "MIN_MAX"
    },
    "dataset_stats": {
      "observation.images.front": {
        "mean": [
          0.485,
          0.456,
          0.406
        ],
        "std": [
          0.229,
          0.224,
          0.225
        ]
      },
      "observation.images.wrist": {
        "mean": [
          0.485,
          0.456,
          0.406
        ],
        "std": [
          0.229,
          0.224,
          0.225
        ]
      },
      "observation.state": {
        "min": [
          -120.0,
          -110.0,
          -110.0,
          -120.0,
          -120.0,
          0.0
        ],
        "max": [
          120.0,
          110.0,
          110.0,
          120.0,
          120.0,
          100.0
        ]
      },
      "action": {
        "min": [
          -1.0,
          -1.0,
          -1.0,
          0.0
        ],
        "max": [
          1.0,
          1.0,
          1.0,
          2.0
        ]
      }
    },
    "device": "cuda",
    "storage_device": "cuda",
    "use_amp": false,
    "vision_encoder_name": "helper2424/resnet10",
    "freeze_vision_encoder": false,
    "image_encoder_hidden_dim": 32,
    "shared_encoder": true,
    "image_embedding_pooling_dim": 8,
    "online_steps": 1000000,
    "online_buffer_capacity": 150000,
    "offline_buffer_capacity": 150000,
    "async_prefetch": false,
    "online_step_before_learning": 500,
    "policy_update_freq": 1,
    "discount": 0.99,
    "temperature_init": 1.0,
    "num_critics": 2,
    "critic_lr": 0.0003,
    "actor_lr": 0.0003,
    "temperature_lr": 0.0003,
    "critic_target_update_weight": 0.005,
    "utd_ratio": 1,
    "state_encoder_hidden_dim": 256,
    "latent_dim": 256,
    "target_entropy": null,
    "use_backup_entropy": true,
    "grad_clip_norm": 40.0,
    "critic_network_kwargs": {
      "hidden_dims": [
        256,
        256
      ],
      "activate_final": true,
      "final_activation": null
    },
    "actor_network_kwargs": {
      "hidden_dims": [
        256,
        256
      ],
      "activate_final": true
    },
    "policy_kwargs": {
      "use_tanh_squash": true,
      "std_min": -5.0,
      "std_max": 2.0,
      "init_final": 0.05
    },
    "actor_learner_config": {
      "learner_host": "127.0.0.1",
      "learner_port": 50051,
      "policy_parameters_push_frequency": 4,
      "queue_get_timeout": 2.0
    },
    "concurrency": {
      "actor": "threads",
      "learner": "threads"
    },
    "push_to_hub": false,
    "repo_id": null,
    "tags": [
      "hil-serl",
      "so101"
    ],
    "pretrained_path": "/home/daniel/lerobot/outputs/train/GrabBlock1/checkpoints/last/pretrained_model",
    "use_torch_compile": true
  },
  "env": {
    "type": "gym_manipulator",
    "name": "real_robot",
    "fps": 10,
    "robot": {
      "type": "so101_follower",
      "id": "follower_white",
      "port": "/dev/ttyACM1",
      "use_degrees": false,
      "max_relative_target": 12.0,
      "cameras": {
        "front": {
          "type": "opencv",
          "index_or_path": "/dev/video0",
          "width": 640,
          "height": 480,
          "fps": 30
        },
        "wrist": {
          "type": "opencv",
          "index_or_path": "/dev/video1",
          "width": 640,
          "height": 480,
          "fps": 30
        }
      }
    },
    "teleop": {
      "type": "so101_leader",
      "id": "leader_white",
      "port": "/dev/ttyACM0",
      "use_degrees": true
    },
    "processor": {
      "control_mode": "leader",
      "observation": {
        "display_cameras": false,
        "add_joint_velocity_to_observation": true,
        "add_current_to_observation": true
      },
      "image_preprocessing": {
        "crop_params_dict": null,
        "resize_size": [
          128,
          128
        ]
      },
      "gripper": {
        "use_gripper": true,
        "gripper_penalty": -0.02
      },
      "reset": {
        "fixed_reset_joint_positions": null,
        "reset_time_s": 3.0,
        "control_time_s": 25.0,
        "terminate_on_success": true
      },
      "inverse_kinematics": {
        "urdf_path": "/home/daniel/SO-ARM100/Simulation/SO101/so101_new_calib.urdf",
        "target_frame_name": "gripper_frame_link",
        "end_effector_bounds": {
          "min": [
            0.19,
            -0.08,
            0.0
          ],
          "max": [
            0.27,
            0.08,
            0.12
          ]
        },
        "end_effector_step_sizes": {
          "x": 0.02,
          "y": 0.02,
          "z": 0.02
        }
      },
      "reward_classifier": {
        "pretrained_path": null,
        "success_threshold": 0.7,
        "success_reward": 1.0
      },
      "max_gripper_pos": 30.0
    },
    "features": {
      "observation.images.front": {
        "type": "VISUAL",
        "shape": [
          3,
          128,
          128
        ]
      },
      "observation.images.wrist": {
        "type": "VISUAL",
        "shape": [
          3,
          128,
          128
        ]
      },
      "observation.state": {
        "type": "STATE",
        "shape": [
          6
        ]
      },
      "action": {
        "type": "ACTION",
        "shape": [
          4
        ]
      }
    },
    "features_map": {
      "observation.images.front": "observation.images.front",
      "observation.images.wrist": "observation.images.wrist",
      "observation.state": "observation.state",
      "action": "action"
    }
  }
}
